{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **DS 340W Modified Implementation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Import Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from datetime import datetime, timedelta\n",
    "import yfinance as yf\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Get Environment for API Secret**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Connect to Guardian API for News Articles about Specific Companies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Apple articles to data\\guardian_apple_articles.csv\n",
      "Saved Tesla articles to data\\guardian_tesla_articles.csv\n",
      "Saved Amazon articles to data\\guardian_amazon_articles.csv\n"
     ]
    }
   ],
   "source": [
    "def get_guardian_articles(query, start_date, end_date, api_key, max_pages=100):\n",
    "    url = \"https://content.guardianapis.com/search\"\n",
    "    news_data = []\n",
    "    page_size = 50 \n",
    "    \n",
    "    page = 1\n",
    "    while page <= max_pages:\n",
    "        params = {\n",
    "            'q': query,\n",
    "            'from-date': start_date,\n",
    "            'to-date': end_date,\n",
    "            'api-key': api_key,\n",
    "            'page': page,\n",
    "            'page-size': page_size\n",
    "        }\n",
    "        \n",
    "        response = requests.get(url, params=params)\n",
    "        data = response.json()\n",
    "        \n",
    "        articles = data['response']['results']\n",
    "        \n",
    "        for article in articles:\n",
    "            news_data.append({\n",
    "                'title': article['webTitle'],\n",
    "                'url': article['webUrl'],\n",
    "                'publishedAt': article['webPublicationDate']\n",
    "            })\n",
    "        \n",
    "        ## PAGINATION\n",
    "        if not data['response']['pages'] > page:\n",
    "            break\n",
    "        \n",
    "        page += 1\n",
    "        sleep(0.5) # RATE LIMITS \n",
    "    \n",
    "    return pd.DataFrame(news_data)\n",
    "\n",
    "start_date = '2019-12-31' # START DATE\n",
    "end_date = '2020-12-31' # END DATE (2020 FISCAL YEAR)\n",
    "queries = ['Apple', 'Tesla', 'Amazon']\n",
    "\n",
    "output_dir = \"data\"\n",
    "os.makedirs(output_dir, exist_ok=True) # MAKE DATA DIRECTORY\n",
    "\n",
    "for query in queries:\n",
    "    year_start = datetime.strptime(start_date, \"%Y-%m-%d\") # PROPER QUERY FORMAT FOR DATES\n",
    "    year_end = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "    all_articles = pd.DataFrame()\n",
    "\n",
    "    while year_start < year_end:\n",
    "        next_year_end = min(year_start + timedelta(days=365), year_end) # 365 DAYS + START DATE\n",
    "        articles_df = get_guardian_articles(query, year_start.strftime(\"%Y-%m-%d\"), \n",
    "                                            next_year_end.strftime(\"%Y-%m-%d\"), \n",
    "                                            api_key, max_pages=100)\n",
    "        all_articles = pd.concat([all_articles, articles_df], ignore_index=True)\n",
    "        year_start = next_year_end + timedelta(days=1)\n",
    "\n",
    "    # SAVE FILES TO CSVS\n",
    "    file_name = f\"guardian_{query.lower()}_articles.csv\"\n",
    "    file_path = os.path.join(output_dir, file_name)\n",
    "    all_articles.to_csv(file_path, index=False)\n",
    "\n",
    "    print(f\"Saved {query} articles to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Download 2019-2020 Stock Data for Tesla, Apple, and Amazon**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_fill_stock_data(symbol, start_date, end_date):\n",
    "    stock_data = yf.download(symbol, start=start_date, end=end_date) # YAHOO FINANCE STOCK DATA\n",
    "\n",
    "    all_dates = pd.date_range(start=start_date, end=end_date, freq='B')  # ONLY BUSINESS DAYS (WEEKDAYS)\n",
    "    stock_data = stock_data.reindex(all_dates)\n",
    "\n",
    "    stock_data['Close'] = stock_data['Close'].fillna(method='ffill') # FORWARD FILL (FILL ANY MISSING DATES W PREVIOUS DATE)\n",
    " \n",
    "    stock_data['Close'] = stock_data['Close'].fillna(method='bfill') # EXCEPTION HANDLER IN CASE FFILL DOESN'T WORK\n",
    "\n",
    "    return stock_data\n",
    "\n",
    "output_dir = \"data\"\n",
    "os.makedirs(output_dir, exist_ok=True) # DATA FOLDER\n",
    "\n",
    "symbols = [\"AAPL\", \"AMZN\", \"TSLA\"] # STOCKS ANALYZED\n",
    "start_date = \"2019-12-31\"\n",
    "end_date = \"2020-12-31\"\n",
    "\n",
    "for symbol in symbols: # DOWNLOADER FOR EACH STOCK\n",
    "    stock_data = download_and_fill_stock_data(symbol, start_date, end_date)\n",
    "    \n",
    "    file_name = f\"{symbol.lower()}_stock_data_2019_2020.csv\"\n",
    "    file_path = os.path.join(output_dir, file_name)\n",
    "    \n",
    "    stock_data.to_csv(file_path) # SAVE TO CSV\n",
    "    \n",
    "    print(f\"Saved {symbol} stock data to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment') # PRE TRAINED BERT MODEL FOR SENTIMENT ANALYSIS\n",
    "model = BertForSequenceClassification.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
    "\n",
    "stock_data_apple = pd.read_csv('data/aapl_stock_data_2019_2020.csv', index_col='Date', parse_dates=True) # READ HISTORICAL STOCK DATA\n",
    "stock_data_amazon = pd.read_csv('data/amzn_stock_data_2019_2020.csv', index_col='Date', parse_dates=True)\n",
    "stock_data_tesla = pd.read_csv('data/tsla_stock_data_2019_2020.csv', index_col='Date', parse_dates=True)\n",
    "\n",
    "stock_data_apple = stock_data_apple.sort_index() # SORT BY DATE (INDEX COLUMN)\n",
    "stock_data_amazon = stock_data_amazon.sort_index()\n",
    "stock_data_tesla = stock_data_tesla.sort_index()\n",
    "\n",
    "# ARTICLES FOR ALL COMPANIES\n",
    "df_apple = pd.read_csv(\"data/guardian_apple_articles.csv\")\n",
    "df_amazon = pd.read_csv(\"data/guardian_amazon_articles.csv\")\n",
    "df_tesla = pd.read_csv(\"data/guardian_tesla_articles.csv\")\n",
    "\n",
    "titles_apple = df_apple['title'].tolist()\n",
    "dates_apple = df_apple['publishedAt'].tolist()\n",
    "\n",
    "titles_amazon = df_amazon['title'].tolist()\n",
    "dates_amazon = df_amazon['publishedAt'].tolist()\n",
    "\n",
    "titles_tesla = df_tesla['title'].tolist()\n",
    "dates_tesla = df_tesla['publishedAt'].tolist()\n",
    "\n",
    "for stock_data in [stock_data_apple, stock_data_amazon, stock_data_tesla]:\n",
    "    if stock_data.index.tz is not None: # ACCOUNT FOR TIME ZONE NAIVE/AWARE (FOR NO ERRORS)\n",
    "        stock_data.index = stock_data.index.tz_convert(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **EDA With Financial News Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple Financial News Shape:  (1940, 3)\n",
      "Amazon Financial News Shape:  (2113, 3)\n",
      "Tesla Financial News Shape:  (249, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Apple Financial News Shape: \", df_apple.shape)\n",
    "print(\"Amazon Financial News Shape: \", df_amazon.shape)\n",
    "print(\"Tesla Financial News Shape: \", df_tesla.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>publishedAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tesla to raise another $5bn by selling shares</td>\n",
       "      <td>https://www.theguardian.com/technology/2020/de...</td>\n",
       "      <td>2020-12-08T15:09:32Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Elon Musk: I tried to sell Tesla to Apple</td>\n",
       "      <td>https://www.theguardian.com/technology/2020/de...</td>\n",
       "      <td>2020-12-23T02:08:36Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tesla joins Wall Street's S&amp;P 500 share index</td>\n",
       "      <td>https://www.theguardian.com/technology/2020/de...</td>\n",
       "      <td>2020-12-21T16:56:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tesla investor defends electric carmaker's soa...</td>\n",
       "      <td>https://www.theguardian.com/technology/2020/no...</td>\n",
       "      <td>2020-11-06T12:24:55Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tesla review – sparky biopic of the inventor</td>\n",
       "      <td>https://www.theguardian.com/film/2020/sep/20/t...</td>\n",
       "      <td>2020-09-20T10:00:43Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0      Tesla to raise another $5bn by selling shares   \n",
       "1          Elon Musk: I tried to sell Tesla to Apple   \n",
       "2      Tesla joins Wall Street's S&P 500 share index   \n",
       "3  Tesla investor defends electric carmaker's soa...   \n",
       "4       Tesla review – sparky biopic of the inventor   \n",
       "\n",
       "                                                 url           publishedAt  \n",
       "0  https://www.theguardian.com/technology/2020/de...  2020-12-08T15:09:32Z  \n",
       "1  https://www.theguardian.com/technology/2020/de...  2020-12-23T02:08:36Z  \n",
       "2  https://www.theguardian.com/technology/2020/de...  2020-12-21T16:56:00Z  \n",
       "3  https://www.theguardian.com/technology/2020/no...  2020-11-06T12:24:55Z  \n",
       "4  https://www.theguardian.com/film/2020/sep/20/t...  2020-09-20T10:00:43Z  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tesla.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Stock Price Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Price Shape:  (263, 6)\n"
     ]
    }
   ],
   "source": [
    "print(\"Stock Price Shape: \", stock_data_amazon.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>92.099998</td>\n",
       "      <td>92.663002</td>\n",
       "      <td>91.611504</td>\n",
       "      <td>92.391998</td>\n",
       "      <td>92.391998</td>\n",
       "      <td>50130000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92.391998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02</th>\n",
       "      <td>93.750000</td>\n",
       "      <td>94.900497</td>\n",
       "      <td>93.207497</td>\n",
       "      <td>94.900497</td>\n",
       "      <td>94.900497</td>\n",
       "      <td>80580000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>93.224998</td>\n",
       "      <td>94.309998</td>\n",
       "      <td>93.224998</td>\n",
       "      <td>93.748497</td>\n",
       "      <td>93.748497</td>\n",
       "      <td>75288000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-06</th>\n",
       "      <td>93.000000</td>\n",
       "      <td>95.184502</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>95.143997</td>\n",
       "      <td>95.143997</td>\n",
       "      <td>81236000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Open       High        Low      Close  Adj Close      Volume\n",
       "Date                                                                         \n",
       "2019-12-31  92.099998  92.663002  91.611504  92.391998  92.391998  50130000.0\n",
       "2020-01-01        NaN        NaN        NaN  92.391998        NaN         NaN\n",
       "2020-01-02  93.750000  94.900497  93.207497  94.900497  94.900497  80580000.0\n",
       "2020-01-03  93.224998  94.309998  93.224998  93.748497  93.748497  75288000.0\n",
       "2020-01-06  93.000000  95.184502  93.000000  95.143997  95.143997  81236000.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_data_amazon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_price(symbol, date): # STOCK PRICE ON GIVEN DAY\n",
    "    date = pd.to_datetime(date)\n",
    "    \n",
    "    if date.tz is not None:\n",
    "        date = date.tz_convert(None)\n",
    "    \n",
    "    if symbol == \"AAPL\":\n",
    "        stock_data = stock_data_apple\n",
    "    elif symbol == \"AMZN\":\n",
    "        stock_data = stock_data_amazon\n",
    "    elif symbol == \"TSLA\":\n",
    "        stock_data = stock_data_tesla\n",
    "    \n",
    "    if date in stock_data.index:\n",
    "        return stock_data.loc[date, 'Close']\n",
    "    else:\n",
    "        previous_date = stock_data.index[stock_data.index.searchsorted(date) - 1] # USE PREVIOUS DATE IF DATA ISN'T AVAILABLE FOR CURRENT DATE\n",
    "        return stock_data.loc[previous_date, 'Close']\n",
    "\n",
    "def get_price_change(symbol, date): # GET PRICE DIFFERENCE FROM CURRENT DAY - PREVIOUS DAY\n",
    "    today_price = get_stock_price(symbol, date)\n",
    "    if today_price is None:\n",
    "        return None\n",
    "    next_day = pd.to_datetime(date) + pd.DateOffset(days=1)\n",
    "    next_day_str = next_day.strftime('%Y-%m-%d')\n",
    "    \n",
    "    next_day_price = get_stock_price(symbol, next_day_str)\n",
    "    if next_day_price is None:\n",
    "        return None\n",
    "    return 'up' if next_day_price > today_price else 'down'\n",
    "\n",
    "def calculate_accuracy(predictions, articles, symbol): # ACCURACY OF MODEL\n",
    "    correct_predictions = 0\n",
    "    total_predictions = len(predictions)\n",
    "\n",
    "    for idx, (prediction, article_date) in enumerate(zip(predictions, articles)):\n",
    "        price_change = get_price_change(symbol, article_date)\n",
    "        \n",
    "        if price_change is None:\n",
    "            continue\n",
    "\n",
    "        if (prediction == 'positive' and price_change == 'up') or (prediction == 'negative' and price_change == 'down'): # CALCULATE IF CORRECT/INCORRECT\n",
    "            correct_predictions += 1\n",
    "\n",
    "    accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model with K-Fold Cross-Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sentiment prediction accuracy for AAPL (cross-validation): 0.5025773195876289\n",
      "Average sentiment prediction accuracy for AMZN (cross-validation): 0.5390373432825788\n",
      "Average sentiment prediction accuracy for TSLA (cross-validation): 0.5462040816326531\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # GPU OPTIMIZATION\n",
    "model.to(device)\n",
    "\n",
    "def get_sentiment(titles, model, device): # SENTIMENT TAGGING\n",
    "    model.eval()\n",
    "    sentiments = []\n",
    "    \n",
    "    for title in titles:\n",
    "        inputs = tokenizer(title, return_tensors=\"pt\", truncation=True, padding=True, max_length=512).to(device) #FORMAT DATA FOR TENSOR\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        prediction = torch.argmax(outputs.logits).item()\n",
    "        \n",
    "        if prediction == 4:\n",
    "            sentiments.append('positive')\n",
    "        else:\n",
    "            sentiments.append('negative')\n",
    "    \n",
    "    return sentiments\n",
    "\n",
    "def cross_validate(titles, dates, model, device, symbol, n_splits=5): # CROSS VALIDATION FOR N_SPLITS\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42) # KFOLD CV\n",
    "    accuracies = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(titles):\n",
    "        train_titles, test_titles = [titles[i] for i in train_index], [titles[i] for i in test_index]\n",
    "        train_dates, test_dates = [dates[i] for i in train_index], [dates[i] for i in test_index]\n",
    "        \n",
    "        train_predictions = get_sentiment(train_titles, model, device)\n",
    "        test_predictions = get_sentiment(test_titles, model, device) \n",
    "        \n",
    "        accuracy = calculate_accuracy(test_predictions, test_dates, symbol) # CALCULATE ACCURACY FOR KFOLD CV\n",
    "        accuracies.append(accuracy)\n",
    "    \n",
    "    avg_accuracy = np.mean(accuracies) # AVG ACCURACY FOR ALL FOLDS\n",
    "    return avg_accuracy\n",
    "\n",
    "symbols = [\"AAPL\", \"AMZN\", \"TSLA\"]\n",
    "datasets = [\n",
    "    (titles_apple, dates_apple, \"AAPL\"),\n",
    "    (titles_amazon, dates_amazon, \"AMZN\"),\n",
    "    (titles_tesla, dates_tesla, \"TSLA\")\n",
    "]\n",
    "\n",
    "for titles, dates, symbol in datasets:\n",
    "    avg_accuracy = cross_validate(titles, dates, model, device, symbol, n_splits=5) # 5 SPLITS\n",
    "    print(f\"Average sentiment prediction accuracy for {symbol} (cross-validation): {avg_accuracy}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
